{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6263f43f-803b-45fc-bb7e-f80b222ce464",
   "metadata": {},
   "source": [
    "# Implementing GPT 2 from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c5b813-db44-4098-9daa-e1524deaacc1",
   "metadata": {},
   "source": [
    "# A Dummy GPT_2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "619e74e2-76b4-44ff-9e6d-3cb8c4b8652a",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 1024,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"dropout_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c133bc7-3164-43c7-a7a2-5e4d043a12aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DummyGPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.token_embedding = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.positional_embedding = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.dropout_emb = nn.Dropout(cfg[\"dropout_rate\"])\n",
    "\n",
    "        self.transformer_blocks = nn.Sequential(\n",
    "          *[DummyTransformerBlock(cfg)  for _ in range(cfg[\"n_layers\"])])\n",
    "\n",
    "        self.final_layer_norm = DummyLayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        batch_size, seq_len = inputs.shape\n",
    "        token_embeds = self.token_embedding(inputs)\n",
    "        positional_embeds = self.positional_embedding(torch.arange(seq_len, device=inputs.device))\n",
    "        x = token_embeds + positional_embeds\n",
    "        x = self.dropout_emb(x)\n",
    "        x = self.transformer_blocks(x)\n",
    "        x = self.final_layer_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "\n",
    "        return logits\n",
    "        \n",
    "\n",
    "class DummyTransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        return x\n",
    "        \n",
    "class DummyLayerNorm(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        return x    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc6c4c22-e2ec-49ec-802a-e77114d0d9a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6109, 3626, 6100,  345],\n",
       "        [6109, 1110, 6622,  257]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "batch = []\n",
    "\n",
    "text_1 = \"Every effort moves you\"\n",
    "text_2 = \"Every day holds a\"\n",
    "\n",
    "batch.append(torch.tensor(tokenizer.encode(text_1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(text_2)))\n",
    "\n",
    "batch = torch.stack(batch, dim=0)\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de296578-eb28-4092-9391-694230f5e7ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 50257])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = DummyGPTModel(cfg=GPT_CONFIG_124M)\n",
    "logits = model(batch)\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a29daa-7c87-4b57-ac81-61f286e7d787",
   "metadata": {},
   "source": [
    "# Layer Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80ae5a36-8cd3-4f48-9b07-4c5f2a51eca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1115,  0.1204, -0.3696, -0.2404, -1.1969],\n",
       "        [ 0.2093, -0.9724, -0.7550,  0.3239, -0.1085]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "batch_example = torch.randn(2, 5) #token with 5 embed_dim\n",
    "batch_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4edcc36-e8e7-4cc6-9675-15a8a21aabca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
       "        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
       "       grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = nn.Sequential(nn.Linear(5, 6), nn.ReLU())\n",
    "output = layer(batch_example)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "328d0cb3-661c-47ca-ac28-9495a56fc4f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1324],\n",
       "        [0.2170]], grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = output.mean(dim=-1, keepdim=True)\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dad982d3-a86d-49d3-af65-b3dd735c0712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0231],\n",
       "        [0.0398]], grad_fn=<VarBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variance = output.var(dim=-1, keepdim=True)\n",
    "variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2e24dbc4-5824-46db-a6a3-63ea0ce615a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    -0.0000],\n",
       "        [     0.0000]], grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized = ((output - mean) / torch.sqrt(variance))\n",
    "    \n",
    "normalized.mean(dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e94b22d5-dfa7-4303-9d03-15ae5253c3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7e1fe397-5ae1-44e5-9122-d58f57380780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000],\n",
       "        [1.0000]], grad_fn=<VarBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized.var(dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "723c90fa-37d8-4888-bcf6-5bcc49c9bb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var =  x.var(dim=-1, keepdim=True)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "\n",
    "        return self.scale * norm_x + self.shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "28992704-13c5-4d70-a100-8106c7f40b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6157,  1.4123, -0.8717,  0.5871, -0.8717, -0.8717],\n",
       "        [-0.0189,  0.1121, -1.0875,  1.5171,  0.5647, -1.0875]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_norm = LayerNorm(6)\n",
    "norm_output = layer_norm(output)\n",
    "norm_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4fc546-b615-4e5d-9342-8b9fb459dc67",
   "metadata": {},
   "source": [
    "# Feed Forward Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f4acabfe-e57c-4fcd-ae44-b378e07957ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
    "            (x + 0.44715 * torch.pow(x, 3))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b9f4718c-d60a-4463-9480-25606dc6345f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNetwork(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"])\n",
    "        )\n",
    "\n",
    "    def forward(self, x):  \n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5db7787d-d3ab-41ce-b142-6dc0c467782f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 768])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffn = FeedForwardNetwork(cfg=GPT_CONFIG_124M)\n",
    "\n",
    "x = torch.rand(2, 3, 768)\n",
    "ffn(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2fe5684c-afb0-49c3-8938-4074367d688f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "  (1): GELU()\n",
       "  (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffn.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e050048-7712-4daf-836c-b949c5600c53",
   "metadata": {},
   "source": [
    "# Transformer Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1a7fcba9-229b-405e-ab8c-a04a15c66402",
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import MultiHeadAttention\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(\n",
    "            d_in = cfg[\"emb_dim\"],\n",
    "            d_out = cfg[\"emb_dim\"],\n",
    "            context_length = cfg[\"context_length\"],\n",
    "            dropout = cfg[\"dropout_rate\"],\n",
    "            num_heads = cfg[\"n_heads\"],\n",
    "            qkv_bias = cfg[\"qkv_bias\"]\n",
    "        )\n",
    "        self.ffn = FeedForwardNetwork(cfg)\n",
    "        self.layer_norm_1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.layer_norm_2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.dropout_shortcut = nn.Dropout(cfg[\"dropout_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        x = self.layer_norm_1(x)\n",
    "        x = self.mha(x)\n",
    "        x = self.dropout_shortcut(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        shorcut = x\n",
    "        x = self.layer_norm_2(x)\n",
    "        x = self.ffn(x)\n",
    "        x = self.dropout_shortcut(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8e4f0f7e-5f35-4aba-9f0a-251a04559fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 12, 4, 64])\n",
      "torch.Size([2, 12, 4, 4])\n",
      "torch.Size([2, 12, 4, 4])\n",
      "torch.Size([2, 4, 12, 64])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 768])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "x = torch.randn(2, 4, 768)\n",
    "tf_block = TransformerBlock(cfg=GPT_CONFIG_124M)\n",
    "\n",
    "output = tf_block(x)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffd2aaf-a51a-456d-bdc9-c6b6592d12e6",
   "metadata": {},
   "source": [
    "# Original GPT 2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5bc270ff-3728-4368-a777-74f859b50d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6109, 3626, 6100,  345],\n",
       "        [6109, 1110, 6622,  257]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "batch = []\n",
    "\n",
    "text_1 = \"Every effort moves you\"\n",
    "text_2 = \"Every day holds a\"\n",
    "\n",
    "batch.append(torch.tensor(tokenizer.encode(text_1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(text_2)))\n",
    "\n",
    "batch = torch.stack(batch, dim=0)\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "87b77176-2ba6-4902-be47-1d5a4cb17ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.token_embedding = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.positional_embedding = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.dropout_emb = nn.Dropout(cfg[\"dropout_rate\"])\n",
    "\n",
    "        self.transformer_blocks = nn.Sequential(\n",
    "          *[TransformerBlock(cfg)  for _ in range(cfg[\"n_layers\"])])\n",
    "\n",
    "        self.final_layer_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        batch_size, seq_len = inputs.shape\n",
    "        token_embeds = self.token_embedding(inputs)\n",
    "        positional_embeds = self.positional_embedding(torch.arange(seq_len, device=inputs.device))\n",
    "        x = token_embeds + positional_embeds\n",
    "        x = self.dropout_emb(x)\n",
    "        x = self.transformer_blocks(x)\n",
    "        x = self.final_layer_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0b3d8bd7-8559-479b-8602-0eba2b808b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 12, 4, 64])\n",
      "torch.Size([2, 12, 4, 4])\n",
      "torch.Size([2, 12, 4, 4])\n",
      "torch.Size([2, 4, 12, 64])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 12, 4, 64])\n",
      "torch.Size([2, 12, 4, 4])\n",
      "torch.Size([2, 12, 4, 4])\n",
      "torch.Size([2, 4, 12, 64])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 12, 4, 64])\n",
      "torch.Size([2, 12, 4, 4])\n",
      "torch.Size([2, 12, 4, 4])\n",
      "torch.Size([2, 4, 12, 64])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 12, 4, 64])\n",
      "torch.Size([2, 12, 4, 4])\n",
      "torch.Size([2, 12, 4, 4])\n",
      "torch.Size([2, 4, 12, 64])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 12, 4, 64])\n",
      "torch.Size([2, 12, 4, 4])\n",
      "torch.Size([2, 12, 4, 4])\n",
      "torch.Size([2, 4, 12, 64])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 12, 4, 64])\n",
      "torch.Size([2, 12, 4, 4])\n",
      "torch.Size([2, 12, 4, 4])\n",
      "torch.Size([2, 4, 12, 64])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 12, 4, 64])\n",
      "torch.Size([2, 12, 4, 4])\n",
      "torch.Size([2, 12, 4, 4])\n",
      "torch.Size([2, 4, 12, 64])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 12, 4, 64])\n",
      "torch.Size([2, 12, 4, 4])\n",
      "torch.Size([2, 12, 4, 4])\n",
      "torch.Size([2, 4, 12, 64])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 12, 4, 64])\n",
      "torch.Size([2, 12, 4, 4])\n",
      "torch.Size([2, 12, 4, 4])\n",
      "torch.Size([2, 4, 12, 64])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 12, 4, 64])\n",
      "torch.Size([2, 12, 4, 4])\n",
      "torch.Size([2, 12, 4, 4])\n",
      "torch.Size([2, 4, 12, 64])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 12, 4, 64])\n",
      "torch.Size([2, 12, 4, 4])\n",
      "torch.Size([2, 12, 4, 4])\n",
      "torch.Size([2, 4, 12, 64])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 12, 4, 64])\n",
      "torch.Size([2, 12, 4, 4])\n",
      "torch.Size([2, 12, 4, 4])\n",
      "torch.Size([2, 4, 12, 64])\n",
      "torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 50257])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "model = GPTModel(cfg=GPT_CONFIG_124M)\n",
    "output = model(batch)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9764d881-9e77-417b-a7e4-856f2b3a558b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "35ceae28-d1db-4b5a-8b0f-1bf82972159f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163,009,536\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"{total_params:,}\") #weight sharing in original gpt model emb layer and out_head layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "df697be8-f7bf-4403-b79a-67d267437567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124412160"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_params - model.token_embedding.weight.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b663c8-8b95-4ce2-a68a-5c49eba3abe7",
   "metadata": {},
   "source": [
    "# Generating Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bc3b0983-793a-4130-98b0-424efb62308c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_context = \"Hello, I am\"\n",
    "\n",
    "encoded = tokenizer.encode(start_context)\n",
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "encoded_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "98c2bfed-fa3b-4042-bf93-d69642f08783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, idx, max_new_tokens, context_size):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "        probas = torch.softmax(logits, dim=-1)\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "    return idx\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ecdcac40-1610-47f1-b2f1-ebec8b4504db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 12, 4, 64])\n",
      "torch.Size([1, 12, 4, 4])\n",
      "torch.Size([1, 12, 4, 4])\n",
      "torch.Size([1, 4, 12, 64])\n",
      "torch.Size([1, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "torch.Size([1, 12, 4, 64])\n",
      "torch.Size([1, 12, 4, 4])\n",
      "torch.Size([1, 12, 4, 4])\n",
      "torch.Size([1, 4, 12, 64])\n",
      "torch.Size([1, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "torch.Size([1, 12, 4, 64])\n",
      "torch.Size([1, 12, 4, 4])\n",
      "torch.Size([1, 12, 4, 4])\n",
      "torch.Size([1, 4, 12, 64])\n",
      "torch.Size([1, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "torch.Size([1, 12, 4, 64])\n",
      "torch.Size([1, 12, 4, 4])\n",
      "torch.Size([1, 12, 4, 4])\n",
      "torch.Size([1, 4, 12, 64])\n",
      "torch.Size([1, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "torch.Size([1, 12, 4, 64])\n",
      "torch.Size([1, 12, 4, 4])\n",
      "torch.Size([1, 12, 4, 4])\n",
      "torch.Size([1, 4, 12, 64])\n",
      "torch.Size([1, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "torch.Size([1, 12, 4, 64])\n",
      "torch.Size([1, 12, 4, 4])\n",
      "torch.Size([1, 12, 4, 4])\n",
      "torch.Size([1, 4, 12, 64])\n",
      "torch.Size([1, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "torch.Size([1, 12, 4, 64])\n",
      "torch.Size([1, 12, 4, 4])\n",
      "torch.Size([1, 12, 4, 4])\n",
      "torch.Size([1, 4, 12, 64])\n",
      "torch.Size([1, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "torch.Size([1, 12, 4, 64])\n",
      "torch.Size([1, 12, 4, 4])\n",
      "torch.Size([1, 12, 4, 4])\n",
      "torch.Size([1, 4, 12, 64])\n",
      "torch.Size([1, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "torch.Size([1, 12, 4, 64])\n",
      "torch.Size([1, 12, 4, 4])\n",
      "torch.Size([1, 12, 4, 4])\n",
      "torch.Size([1, 4, 12, 64])\n",
      "torch.Size([1, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "torch.Size([1, 12, 4, 64])\n",
      "torch.Size([1, 12, 4, 4])\n",
      "torch.Size([1, 12, 4, 4])\n",
      "torch.Size([1, 4, 12, 64])\n",
      "torch.Size([1, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "torch.Size([1, 12, 4, 64])\n",
      "torch.Size([1, 12, 4, 4])\n",
      "torch.Size([1, 12, 4, 4])\n",
      "torch.Size([1, 4, 12, 64])\n",
      "torch.Size([1, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "torch.Size([1, 12, 4, 64])\n",
      "torch.Size([1, 12, 4, 4])\n",
      "torch.Size([1, 12, 4, 4])\n",
      "torch.Size([1, 4, 12, 64])\n",
      "torch.Size([1, 4, 768])\n",
      "torch.Size([1, 4, 768])\n",
      "torch.Size([1, 12, 5, 64])\n",
      "torch.Size([1, 12, 5, 5])\n",
      "torch.Size([1, 12, 5, 5])\n",
      "torch.Size([1, 5, 12, 64])\n",
      "torch.Size([1, 5, 768])\n",
      "torch.Size([1, 5, 768])\n",
      "torch.Size([1, 12, 5, 64])\n",
      "torch.Size([1, 12, 5, 5])\n",
      "torch.Size([1, 12, 5, 5])\n",
      "torch.Size([1, 5, 12, 64])\n",
      "torch.Size([1, 5, 768])\n",
      "torch.Size([1, 5, 768])\n",
      "torch.Size([1, 12, 5, 64])\n",
      "torch.Size([1, 12, 5, 5])\n",
      "torch.Size([1, 12, 5, 5])\n",
      "torch.Size([1, 5, 12, 64])\n",
      "torch.Size([1, 5, 768])\n",
      "torch.Size([1, 5, 768])\n",
      "torch.Size([1, 12, 5, 64])\n",
      "torch.Size([1, 12, 5, 5])\n",
      "torch.Size([1, 12, 5, 5])\n",
      "torch.Size([1, 5, 12, 64])\n",
      "torch.Size([1, 5, 768])\n",
      "torch.Size([1, 5, 768])\n",
      "torch.Size([1, 12, 5, 64])\n",
      "torch.Size([1, 12, 5, 5])\n",
      "torch.Size([1, 12, 5, 5])\n",
      "torch.Size([1, 5, 12, 64])\n",
      "torch.Size([1, 5, 768])\n",
      "torch.Size([1, 5, 768])\n",
      "torch.Size([1, 12, 5, 64])\n",
      "torch.Size([1, 12, 5, 5])\n",
      "torch.Size([1, 12, 5, 5])\n",
      "torch.Size([1, 5, 12, 64])\n",
      "torch.Size([1, 5, 768])\n",
      "torch.Size([1, 5, 768])\n",
      "torch.Size([1, 12, 5, 64])\n",
      "torch.Size([1, 12, 5, 5])\n",
      "torch.Size([1, 12, 5, 5])\n",
      "torch.Size([1, 5, 12, 64])\n",
      "torch.Size([1, 5, 768])\n",
      "torch.Size([1, 5, 768])\n",
      "torch.Size([1, 12, 5, 64])\n",
      "torch.Size([1, 12, 5, 5])\n",
      "torch.Size([1, 12, 5, 5])\n",
      "torch.Size([1, 5, 12, 64])\n",
      "torch.Size([1, 5, 768])\n",
      "torch.Size([1, 5, 768])\n",
      "torch.Size([1, 12, 5, 64])\n",
      "torch.Size([1, 12, 5, 5])\n",
      "torch.Size([1, 12, 5, 5])\n",
      "torch.Size([1, 5, 12, 64])\n",
      "torch.Size([1, 5, 768])\n",
      "torch.Size([1, 5, 768])\n",
      "torch.Size([1, 12, 5, 64])\n",
      "torch.Size([1, 12, 5, 5])\n",
      "torch.Size([1, 12, 5, 5])\n",
      "torch.Size([1, 5, 12, 64])\n",
      "torch.Size([1, 5, 768])\n",
      "torch.Size([1, 5, 768])\n",
      "torch.Size([1, 12, 5, 64])\n",
      "torch.Size([1, 12, 5, 5])\n",
      "torch.Size([1, 12, 5, 5])\n",
      "torch.Size([1, 5, 12, 64])\n",
      "torch.Size([1, 5, 768])\n",
      "torch.Size([1, 5, 768])\n",
      "torch.Size([1, 12, 5, 64])\n",
      "torch.Size([1, 12, 5, 5])\n",
      "torch.Size([1, 12, 5, 5])\n",
      "torch.Size([1, 5, 12, 64])\n",
      "torch.Size([1, 5, 768])\n",
      "torch.Size([1, 5, 768])\n",
      "torch.Size([1, 12, 6, 64])\n",
      "torch.Size([1, 12, 6, 6])\n",
      "torch.Size([1, 12, 6, 6])\n",
      "torch.Size([1, 6, 12, 64])\n",
      "torch.Size([1, 6, 768])\n",
      "torch.Size([1, 6, 768])\n",
      "torch.Size([1, 12, 6, 64])\n",
      "torch.Size([1, 12, 6, 6])\n",
      "torch.Size([1, 12, 6, 6])\n",
      "torch.Size([1, 6, 12, 64])\n",
      "torch.Size([1, 6, 768])\n",
      "torch.Size([1, 6, 768])\n",
      "torch.Size([1, 12, 6, 64])\n",
      "torch.Size([1, 12, 6, 6])\n",
      "torch.Size([1, 12, 6, 6])\n",
      "torch.Size([1, 6, 12, 64])\n",
      "torch.Size([1, 6, 768])\n",
      "torch.Size([1, 6, 768])\n",
      "torch.Size([1, 12, 6, 64])\n",
      "torch.Size([1, 12, 6, 6])\n",
      "torch.Size([1, 12, 6, 6])\n",
      "torch.Size([1, 6, 12, 64])\n",
      "torch.Size([1, 6, 768])\n",
      "torch.Size([1, 6, 768])\n",
      "torch.Size([1, 12, 6, 64])\n",
      "torch.Size([1, 12, 6, 6])\n",
      "torch.Size([1, 12, 6, 6])\n",
      "torch.Size([1, 6, 12, 64])\n",
      "torch.Size([1, 6, 768])\n",
      "torch.Size([1, 6, 768])\n",
      "torch.Size([1, 12, 6, 64])\n",
      "torch.Size([1, 12, 6, 6])\n",
      "torch.Size([1, 12, 6, 6])\n",
      "torch.Size([1, 6, 12, 64])\n",
      "torch.Size([1, 6, 768])\n",
      "torch.Size([1, 6, 768])\n",
      "torch.Size([1, 12, 6, 64])\n",
      "torch.Size([1, 12, 6, 6])\n",
      "torch.Size([1, 12, 6, 6])\n",
      "torch.Size([1, 6, 12, 64])\n",
      "torch.Size([1, 6, 768])\n",
      "torch.Size([1, 6, 768])\n",
      "torch.Size([1, 12, 6, 64])\n",
      "torch.Size([1, 12, 6, 6])\n",
      "torch.Size([1, 12, 6, 6])\n",
      "torch.Size([1, 6, 12, 64])\n",
      "torch.Size([1, 6, 768])\n",
      "torch.Size([1, 6, 768])\n",
      "torch.Size([1, 12, 6, 64])\n",
      "torch.Size([1, 12, 6, 6])\n",
      "torch.Size([1, 12, 6, 6])\n",
      "torch.Size([1, 6, 12, 64])\n",
      "torch.Size([1, 6, 768])\n",
      "torch.Size([1, 6, 768])\n",
      "torch.Size([1, 12, 6, 64])\n",
      "torch.Size([1, 12, 6, 6])\n",
      "torch.Size([1, 12, 6, 6])\n",
      "torch.Size([1, 6, 12, 64])\n",
      "torch.Size([1, 6, 768])\n",
      "torch.Size([1, 6, 768])\n",
      "torch.Size([1, 12, 6, 64])\n",
      "torch.Size([1, 12, 6, 6])\n",
      "torch.Size([1, 12, 6, 6])\n",
      "torch.Size([1, 6, 12, 64])\n",
      "torch.Size([1, 6, 768])\n",
      "torch.Size([1, 6, 768])\n",
      "torch.Size([1, 12, 6, 64])\n",
      "torch.Size([1, 12, 6, 6])\n",
      "torch.Size([1, 12, 6, 6])\n",
      "torch.Size([1, 6, 12, 64])\n",
      "torch.Size([1, 6, 768])\n",
      "torch.Size([1, 6, 768])\n",
      "torch.Size([1, 12, 7, 64])\n",
      "torch.Size([1, 12, 7, 7])\n",
      "torch.Size([1, 12, 7, 7])\n",
      "torch.Size([1, 7, 12, 64])\n",
      "torch.Size([1, 7, 768])\n",
      "torch.Size([1, 7, 768])\n",
      "torch.Size([1, 12, 7, 64])\n",
      "torch.Size([1, 12, 7, 7])\n",
      "torch.Size([1, 12, 7, 7])\n",
      "torch.Size([1, 7, 12, 64])\n",
      "torch.Size([1, 7, 768])\n",
      "torch.Size([1, 7, 768])\n",
      "torch.Size([1, 12, 7, 64])\n",
      "torch.Size([1, 12, 7, 7])\n",
      "torch.Size([1, 12, 7, 7])\n",
      "torch.Size([1, 7, 12, 64])\n",
      "torch.Size([1, 7, 768])\n",
      "torch.Size([1, 7, 768])\n",
      "torch.Size([1, 12, 7, 64])\n",
      "torch.Size([1, 12, 7, 7])\n",
      "torch.Size([1, 12, 7, 7])\n",
      "torch.Size([1, 7, 12, 64])\n",
      "torch.Size([1, 7, 768])\n",
      "torch.Size([1, 7, 768])\n",
      "torch.Size([1, 12, 7, 64])\n",
      "torch.Size([1, 12, 7, 7])\n",
      "torch.Size([1, 12, 7, 7])\n",
      "torch.Size([1, 7, 12, 64])\n",
      "torch.Size([1, 7, 768])\n",
      "torch.Size([1, 7, 768])\n",
      "torch.Size([1, 12, 7, 64])\n",
      "torch.Size([1, 12, 7, 7])\n",
      "torch.Size([1, 12, 7, 7])\n",
      "torch.Size([1, 7, 12, 64])\n",
      "torch.Size([1, 7, 768])\n",
      "torch.Size([1, 7, 768])\n",
      "torch.Size([1, 12, 7, 64])\n",
      "torch.Size([1, 12, 7, 7])\n",
      "torch.Size([1, 12, 7, 7])\n",
      "torch.Size([1, 7, 12, 64])\n",
      "torch.Size([1, 7, 768])\n",
      "torch.Size([1, 7, 768])\n",
      "torch.Size([1, 12, 7, 64])\n",
      "torch.Size([1, 12, 7, 7])\n",
      "torch.Size([1, 12, 7, 7])\n",
      "torch.Size([1, 7, 12, 64])\n",
      "torch.Size([1, 7, 768])\n",
      "torch.Size([1, 7, 768])\n",
      "torch.Size([1, 12, 7, 64])\n",
      "torch.Size([1, 12, 7, 7])\n",
      "torch.Size([1, 12, 7, 7])\n",
      "torch.Size([1, 7, 12, 64])\n",
      "torch.Size([1, 7, 768])\n",
      "torch.Size([1, 7, 768])\n",
      "torch.Size([1, 12, 7, 64])\n",
      "torch.Size([1, 12, 7, 7])\n",
      "torch.Size([1, 12, 7, 7])\n",
      "torch.Size([1, 7, 12, 64])\n",
      "torch.Size([1, 7, 768])\n",
      "torch.Size([1, 7, 768])\n",
      "torch.Size([1, 12, 7, 64])\n",
      "torch.Size([1, 12, 7, 7])\n",
      "torch.Size([1, 12, 7, 7])\n",
      "torch.Size([1, 7, 12, 64])\n",
      "torch.Size([1, 7, 768])\n",
      "torch.Size([1, 7, 768])\n",
      "torch.Size([1, 12, 7, 64])\n",
      "torch.Size([1, 12, 7, 7])\n",
      "torch.Size([1, 12, 7, 7])\n",
      "torch.Size([1, 7, 12, 64])\n",
      "torch.Size([1, 7, 768])\n",
      "torch.Size([1, 7, 768])\n",
      "torch.Size([1, 12, 8, 64])\n",
      "torch.Size([1, 12, 8, 8])\n",
      "torch.Size([1, 12, 8, 8])\n",
      "torch.Size([1, 8, 12, 64])\n",
      "torch.Size([1, 8, 768])\n",
      "torch.Size([1, 8, 768])\n",
      "torch.Size([1, 12, 8, 64])\n",
      "torch.Size([1, 12, 8, 8])\n",
      "torch.Size([1, 12, 8, 8])\n",
      "torch.Size([1, 8, 12, 64])\n",
      "torch.Size([1, 8, 768])\n",
      "torch.Size([1, 8, 768])\n",
      "torch.Size([1, 12, 8, 64])\n",
      "torch.Size([1, 12, 8, 8])\n",
      "torch.Size([1, 12, 8, 8])\n",
      "torch.Size([1, 8, 12, 64])\n",
      "torch.Size([1, 8, 768])\n",
      "torch.Size([1, 8, 768])\n",
      "torch.Size([1, 12, 8, 64])\n",
      "torch.Size([1, 12, 8, 8])\n",
      "torch.Size([1, 12, 8, 8])\n",
      "torch.Size([1, 8, 12, 64])\n",
      "torch.Size([1, 8, 768])\n",
      "torch.Size([1, 8, 768])\n",
      "torch.Size([1, 12, 8, 64])\n",
      "torch.Size([1, 12, 8, 8])\n",
      "torch.Size([1, 12, 8, 8])\n",
      "torch.Size([1, 8, 12, 64])\n",
      "torch.Size([1, 8, 768])\n",
      "torch.Size([1, 8, 768])\n",
      "torch.Size([1, 12, 8, 64])\n",
      "torch.Size([1, 12, 8, 8])\n",
      "torch.Size([1, 12, 8, 8])\n",
      "torch.Size([1, 8, 12, 64])\n",
      "torch.Size([1, 8, 768])\n",
      "torch.Size([1, 8, 768])\n",
      "torch.Size([1, 12, 8, 64])\n",
      "torch.Size([1, 12, 8, 8])\n",
      "torch.Size([1, 12, 8, 8])\n",
      "torch.Size([1, 8, 12, 64])\n",
      "torch.Size([1, 8, 768])\n",
      "torch.Size([1, 8, 768])\n",
      "torch.Size([1, 12, 8, 64])\n",
      "torch.Size([1, 12, 8, 8])\n",
      "torch.Size([1, 12, 8, 8])\n",
      "torch.Size([1, 8, 12, 64])\n",
      "torch.Size([1, 8, 768])\n",
      "torch.Size([1, 8, 768])\n",
      "torch.Size([1, 12, 8, 64])\n",
      "torch.Size([1, 12, 8, 8])\n",
      "torch.Size([1, 12, 8, 8])\n",
      "torch.Size([1, 8, 12, 64])\n",
      "torch.Size([1, 8, 768])\n",
      "torch.Size([1, 8, 768])\n",
      "torch.Size([1, 12, 8, 64])\n",
      "torch.Size([1, 12, 8, 8])\n",
      "torch.Size([1, 12, 8, 8])\n",
      "torch.Size([1, 8, 12, 64])\n",
      "torch.Size([1, 8, 768])\n",
      "torch.Size([1, 8, 768])\n",
      "torch.Size([1, 12, 8, 64])\n",
      "torch.Size([1, 12, 8, 8])\n",
      "torch.Size([1, 12, 8, 8])\n",
      "torch.Size([1, 8, 12, 64])\n",
      "torch.Size([1, 8, 768])\n",
      "torch.Size([1, 8, 768])\n",
      "torch.Size([1, 12, 8, 64])\n",
      "torch.Size([1, 12, 8, 8])\n",
      "torch.Size([1, 12, 8, 8])\n",
      "torch.Size([1, 8, 12, 64])\n",
      "torch.Size([1, 8, 768])\n",
      "torch.Size([1, 8, 768])\n",
      "torch.Size([1, 12, 9, 64])\n",
      "torch.Size([1, 12, 9, 9])\n",
      "torch.Size([1, 12, 9, 9])\n",
      "torch.Size([1, 9, 12, 64])\n",
      "torch.Size([1, 9, 768])\n",
      "torch.Size([1, 9, 768])\n",
      "torch.Size([1, 12, 9, 64])\n",
      "torch.Size([1, 12, 9, 9])\n",
      "torch.Size([1, 12, 9, 9])\n",
      "torch.Size([1, 9, 12, 64])\n",
      "torch.Size([1, 9, 768])\n",
      "torch.Size([1, 9, 768])\n",
      "torch.Size([1, 12, 9, 64])\n",
      "torch.Size([1, 12, 9, 9])\n",
      "torch.Size([1, 12, 9, 9])\n",
      "torch.Size([1, 9, 12, 64])\n",
      "torch.Size([1, 9, 768])\n",
      "torch.Size([1, 9, 768])\n",
      "torch.Size([1, 12, 9, 64])\n",
      "torch.Size([1, 12, 9, 9])\n",
      "torch.Size([1, 12, 9, 9])\n",
      "torch.Size([1, 9, 12, 64])\n",
      "torch.Size([1, 9, 768])\n",
      "torch.Size([1, 9, 768])\n",
      "torch.Size([1, 12, 9, 64])\n",
      "torch.Size([1, 12, 9, 9])\n",
      "torch.Size([1, 12, 9, 9])\n",
      "torch.Size([1, 9, 12, 64])\n",
      "torch.Size([1, 9, 768])\n",
      "torch.Size([1, 9, 768])\n",
      "torch.Size([1, 12, 9, 64])\n",
      "torch.Size([1, 12, 9, 9])\n",
      "torch.Size([1, 12, 9, 9])\n",
      "torch.Size([1, 9, 12, 64])\n",
      "torch.Size([1, 9, 768])\n",
      "torch.Size([1, 9, 768])\n",
      "torch.Size([1, 12, 9, 64])\n",
      "torch.Size([1, 12, 9, 9])\n",
      "torch.Size([1, 12, 9, 9])\n",
      "torch.Size([1, 9, 12, 64])\n",
      "torch.Size([1, 9, 768])\n",
      "torch.Size([1, 9, 768])\n",
      "torch.Size([1, 12, 9, 64])\n",
      "torch.Size([1, 12, 9, 9])\n",
      "torch.Size([1, 12, 9, 9])\n",
      "torch.Size([1, 9, 12, 64])\n",
      "torch.Size([1, 9, 768])\n",
      "torch.Size([1, 9, 768])\n",
      "torch.Size([1, 12, 9, 64])\n",
      "torch.Size([1, 12, 9, 9])\n",
      "torch.Size([1, 12, 9, 9])\n",
      "torch.Size([1, 9, 12, 64])\n",
      "torch.Size([1, 9, 768])\n",
      "torch.Size([1, 9, 768])\n",
      "torch.Size([1, 12, 9, 64])\n",
      "torch.Size([1, 12, 9, 9])\n",
      "torch.Size([1, 12, 9, 9])\n",
      "torch.Size([1, 9, 12, 64])\n",
      "torch.Size([1, 9, 768])\n",
      "torch.Size([1, 9, 768])\n",
      "torch.Size([1, 12, 9, 64])\n",
      "torch.Size([1, 12, 9, 9])\n",
      "torch.Size([1, 12, 9, 9])\n",
      "torch.Size([1, 9, 12, 64])\n",
      "torch.Size([1, 9, 768])\n",
      "torch.Size([1, 9, 768])\n",
      "torch.Size([1, 12, 9, 64])\n",
      "torch.Size([1, 12, 9, 9])\n",
      "torch.Size([1, 12, 9, 9])\n",
      "torch.Size([1, 9, 12, 64])\n",
      "torch.Size([1, 9, 768])\n",
      "torch.Size([1, 9, 768])\n"
     ]
    }
   ],
   "source": [
    "output = generate_text(\n",
    "    model=model,\n",
    "    idx=encoded_tensor,\n",
    "    max_new_tokens=6,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "362c21e6-b946-4117-9aed-4a3e57ea1480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15496,    11,   314,   716,  5466, 43474, 38040, 37516, 10088, 42030]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5f9df054-7563-4cc8-bd93-3e55071189a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, I am sale Discount promul eighty operatorfoundland'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(output.squeeze(0).tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
